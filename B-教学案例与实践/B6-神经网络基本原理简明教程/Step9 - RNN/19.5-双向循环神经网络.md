<!--Copyright © Microsoft Corporation. All rights reserved.
  适用于[License](https://github.com/Microsoft/ai-edu/blob/master/LICENSE.md)版权许可-->

## 19.5 双向循环神经网络



<img src="../Images/19/bi_rnn_net.png" width="500"/>

图一：双向循环神经网络结构图

对于图一中的t2来说，其前向计算公式如下：

$$
h = x \cdot U + s_{t-1} \cdot W \tag{1}
$$

$$
s = \sigma(h) \tag{2}
$$

$$
h' = x \cdot U' + s'_{t+1} \cdot W' \tag{3}
$$

$$
s' = \sigma(h') \tag{4}
$$

$$
z = s \cdot V + s' \cdot V' \tag{5}
$$

$$
a = Softmax(z) \tag{6}
$$

反向传播

$$
\frac{\partial loss}{\partial z}=a-y \rightarrow dz
$$

对于最后一个时间步：

$$
\frac{\partial loss}{\partial h}=\frac{\partial loss}{\partial z}\frac{\partial z}{\partial s}\frac{\partial s}{\partial h}=(a-y)\cdot V^T \odot \sigma'(s) \rightarrow dh
$$

对于前面的时间步：

$$
\begin{aligned}
\frac{\partial Loss}{\partial h_t} &= \frac{\partial loss_t}{\partial z_t}\frac{\partial z_t}{\partial s_t}\frac{\partial s_t}{\partial h_t} + \frac{\partial loss_{t+1}}{\partial z_{t+1}}\frac{\partial z_{t+1}}{\partial s_{t+1}}\frac{\partial s_{t+1}}{\partial h_{t+1}}\frac{\partial h_{t+1}}{\partial s_{t}}\frac{\partial s_t}{\partial h_t}
\\
&=dz_t \cdot V^T \odot \sigma'(s_t) + \frac{\partial loss_{t+1}}{\partial h_{t+1}} \cdot W^T \odot \sigma'(s_t)
\\
&=(dz_t \cdot V^T + dh_{t+1} \cdot W^T) \odot \sigma'(s_t)
\end{aligned}
$$

对于第一个时间步：

$$
\frac{\partial loss}{\partial h'}=\frac{\partial loss}{\partial z}\frac{\partial z}{\partial s'}\frac{\partial s'}{\partial h'}=(a-y)\cdot (V')^T \odot \sigma'(s) \rightarrow dh'
$$

对于后面的时间步：

$$
\begin{aligned}
\frac{\partial Loss}{\partial h'_t} &= \frac{\partial loss_t}{\partial z_t}\frac{\partial z_t}{\partial s'_t}\frac{\partial s'_t}{\partial h'_t} + \frac{\partial loss_{t-1}}{\partial z_{t-1}}\frac{\partial z_{t-1}}{\partial s'_{t-1}}\frac{\partial s'_{t-1}}{\partial h'_{t-1}}\frac{\partial h'_{t-1}}{\partial s'_{t}}\frac{\partial s'_t}{\partial h'_t}
\\
&=dz_t \cdot (V')^T \odot \sigma'(s'_t) + \frac{\partial loss_{t-1}}{\partial h'_{t-1}} \cdot (W')^T \odot \sigma'(s'_t)
\\
&=(dz_t \cdot (V')^T + dh'_{t-1} \cdot (W')^T) \odot \sigma'(s'_t)
\end{aligned}
$$


